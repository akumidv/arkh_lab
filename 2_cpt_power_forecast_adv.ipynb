{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ЛАБОРАТОРИЯ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть III. Продвинутый подход к прогнозированию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оглавление"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Библиотеки и утилиты](#Библиотеки-и-утилиты)\n",
    "\n",
    "[Загрузка данных](#Загрузка-данных)\n",
    "\n",
    "[Взаимосвязь рядов](#Взаимосвязь-рядов)\n",
    "\n",
    "[Формирование данных для обучения](#Формирование-данных-для-обучения)\n",
    "\n",
    "[Обучающая, тестовая и валидационная выборки](#Обучающая,-тестовая-и-валидационная-выборки)\n",
    "\n",
    "[Обучение модели](#Обучение-модели)\n",
    "\n",
    "[Оценка результата](#Оценка-результата)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Библиотеки и утилиты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, LSTM, GRU, TimeDistributed\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from hyperopt import hp, tpe, space_eval\n",
    "from hyperopt.fmin import fmin\n",
    "pd.set_option('display.max_columns', None)\n",
    "print('tensorflow version:', tf.__version__)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpu_devices:\n",
    "    for gpu_device in gpu_devices:\n",
    "        print('device available:', gpu_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = './models_adv'\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    os.mkdir(MODEL_PATH)\n",
    "\n",
    "def set_all_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "set_all_seeds(2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cpt_power_data.csv', sep='\\t', encoding='utf-8', index_col=0)\n",
    "df['timestamp_value'] = pd.to_datetime(df['timestamp_value'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "for ch_serial in df['measuringpoint_serial'].unique():\n",
    "    plt.plot(df[df['measuringpoint_serial'] == ch_serial].timestamp_value, \n",
    "             df[df['measuringpoint_serial'] == ch_serial].value_text, \n",
    "             label=ch_serial)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Взаимосвязь рядов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s = df.pivot('timestamp_value', 'measuringpoint_serial', 'value_text').reset_index()\n",
    "df_s.columns = [df_s.columns[0]] + [df_s.columns.name + '_' + str(col) for col in df_s.columns[1:]]\n",
    "df_s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10 * len(df_s.columns[1:])))\n",
    "for i, col in enumerate(df_s.columns[1:]):\n",
    "    plt.subplot(len(df.columns[1:]), 1, i + 1)\n",
    "    plt.plot(df_s.timestamp_value, df_s[col])\n",
    "    plt.title(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Формирование данных для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_dt = str(df_s.timestamp_value.min())[:10]\n",
    "end_dt = str(df_s.timestamp_value.max())[:10]\n",
    "sequence = df_s.values[:, [1, 2, 4, 6]]\n",
    "dates = df_s['timestamp_value']\n",
    "days_back = 14\n",
    "days_fwd = 14\n",
    "look_back = days_back * 24 * 2\n",
    "look_fwd = days_fwd * 24 * 2\n",
    "start_index = sequence.shape[1]\n",
    "print('start index:', start_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift = -look_fwd\n",
    "df_s['n_day'] = df_s.shift(periods=shift).timestamp_value.dt.day\n",
    "df_s['n_week'] = df_s.shift(periods=shift).timestamp_value.dt.week#.astype(np.int8)\n",
    "df_s['n_month'] = df_s.shift(periods=shift).timestamp_value.dt.month#.astype(np.int8)\n",
    "df_s['w_day'] = df_s.shift(periods=shift).timestamp_value.dt.weekday#.astype(np.int8)\n",
    "df_s['is_weekend'] = (df_s['w_day'] >= 5).astype(np.int8)\n",
    "df_s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequences_feed(sequence, look_back, look_fwd, start_index):\n",
    "    X = []\n",
    "    y = []\n",
    "    length = sequence.shape[0]\n",
    "    for start_x in range(length):\n",
    "        end_x = start_x + look_back\n",
    "        end_y = end_x + look_fwd\n",
    "        if end_y > length:\n",
    "            break\n",
    "        X.append(sequence[start_x:end_x, :])\n",
    "        y.append(sequence[end_x:end_y, :start_index])\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler, scaler_pwr = MinMaxScaler(feature_range=(0, 1)), MinMaxScaler(feature_range=(0, 1))\n",
    "sequence_scaled = scaler_pwr.fit_transform(sequence)\n",
    "with open(f'{MODEL_PATH}/scaler_pwr.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler_pwr, file)\n",
    "print('total elements (pwr):', len(sequence_scaled))\n",
    "print('one element of channel (pwr):', sequence_scaled[0])\n",
    "\n",
    "time_features_scaled = scaler.fit_transform(df_s.iloc[:, -5:])\n",
    "with open(f'{MODEL_PATH}/scaler.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler, file)\n",
    "print('total elements (days features):', len(time_features_scaled))\n",
    "print('one element of channel (days features):', time_features_scaled[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_scaled_exog = np.hstack((sequence_scaled, time_features_scaled))\n",
    "print('shape:', sequence_scaled_exog.shape)\n",
    "print('one row:', sequence_scaled_exog[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = split_sequences_feed(sequence_scaled_exog, look_back, look_fwd, start_index)\n",
    "print('X dataset shape:', X.shape)\n",
    "print('y dataset shape:', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучающая, тестовая и валидационная выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(X, y, train_size=.7):\n",
    "    cut = np.int64(X.shape[0] * train_size)\n",
    "    X_train = X[:cut]\n",
    "    X_test = X[cut:]\n",
    "    y_train = y[:cut]\n",
    "    y_test = y[cut:]\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X[-1][None]\n",
    "y_test = y[-1][None]\n",
    "X_train, X_val, y_train, y_val = get_train_test(X[:-1], y[:-1])\n",
    "print('train shapes:', X_train.shape, y_train.shape)\n",
    "print('validation shapes:', X_val.shape, y_val.shape)\n",
    "print('test shapes:', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features_in = X_train.shape[2]\n",
    "n_features_out = y_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(units, look_back, n_features_in, \n",
    "              dropout, r_dropout, stack=False, loss='mse'):\n",
    "    model = Sequential()\n",
    "    if stack:\n",
    "        model.add(LSTM(units=units, \n",
    "                      input_shape=(look_back, n_features_in), \n",
    "                      activation='relu',\n",
    "                      return_sequences=True, \n",
    "                      dropout=dropout, \n",
    "                      recurrent_dropout=r_dropout))\n",
    "        model.add(LSTM(units=units, \n",
    "                      input_shape=(look_back, n_features_in), \n",
    "                      activation='relu',\n",
    "                      return_sequences=True, \n",
    "                      dropout=dropout, \n",
    "                      recurrent_dropout=r_dropout))\n",
    "    else:\n",
    "        model.add(LSTM(units=units, \n",
    "                      input_shape=(look_back, n_features_in), \n",
    "                      #activation='relu',\n",
    "                      return_sequences=True, \n",
    "                      dropout=dropout, \n",
    "                      recurrent_dropout=r_dropout\n",
    "                     ))\n",
    "    model.add(TimeDistributed(Dense(n_features_out)))\n",
    "    optimizer = optimizers.Adam(lr=.001, clipvalue=.5, clipnorm=1)\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(\n",
    "    units=1024, \n",
    "    look_back=look_back, \n",
    "    n_features_in=n_features_in,\n",
    "    dropout=.25,\n",
    "    r_dropout=0,\n",
    "    stack=False, \n",
    "    loss='mse'\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "checkpoint_path = f'{MODEL_PATH}/model.hdf5'\n",
    "earlystopper = EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        patience=40, \n",
    "        verbose=1,\n",
    "        mode='min'\n",
    ")\n",
    "lrreducer = ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=.1, \n",
    "    patience=20, \n",
    "    verbose=1, \n",
    "    min_lr=1e-6,\n",
    "    mode='min'\n",
    ")\n",
    "checkpointer = ModelCheckpoint(\n",
    "    checkpoint_path, \n",
    "    monitor='val_loss', \n",
    "    verbose=1, \n",
    "    save_best_only=True,\n",
    "    save_weights_only=True, \n",
    "    mode='min'\n",
    ")\n",
    "callbacks = [earlystopper, checkpointer, lrreducer]\n",
    "history = model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    batch_size=256, \n",
    "    epochs=1000, \n",
    "    verbose=1, \n",
    "    validation_data=(X_val, y_val), \n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценка результата"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, X, batch_size=None, n_steps=30 * 24 * 2):\n",
    "    X_i = X\n",
    "    y_pred = []\n",
    "    for i in range(n_steps):\n",
    "        y_pred_i = model.predict(X_i, batch_size=batch_size)\n",
    "        y_pred.append(y_pred_i[0])\n",
    "        X_i = np.hstack((X_i[:, 1:, :], y_pred_i[None, :, :]))\n",
    "    y_pred = np.array(y_pred)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 20))\n",
    "for i in range(y_test[0].shape[1]):\n",
    "    plt.subplot(y_test[0].shape[1], 1, i + 1)\n",
    "    plt.plot(y_test[0][:, i], label='fact')\n",
    "    plt.plot(y_pred[0][:, i], label='prediction')\n",
    "    plt.title(df_s.columns[1:][i], loc='right')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Orange Python 3",
   "language": "python",
   "name": "orange"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
