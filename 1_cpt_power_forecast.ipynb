{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ЛАБОРАТОРИЯ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть II. Первый подход к прогнозированию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оглавление"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Библиотеки и утилиты](#Библиотеки-и-утилиты)\n",
    "\n",
    "[Разбор сырых данных](#Разбор-сырых-данных)\n",
    "\n",
    "[Предварительная обработка и анализ](#Предварительная-обработка-и-анализ)\n",
    "\n",
    "[Визуальный анализ данных](#Визуальный-анализ-данных)\n",
    "\n",
    "[Один ряд как пример](#Один-ряд-как-пример)\n",
    "\n",
    "[Немного новых признаков](#Немного-новых-признаков)\n",
    "\n",
    "[Base-line модель: подготовка данных](#Base-line-модель:-подготовка-данных)\n",
    "\n",
    "[Base-line модель: обучение](#Base-line-модель:-обучение)\n",
    "\n",
    "[ОПЦИОНАЛЬНО: тюнинг base-line модели](#ОПЦИОНАЛЬНО:-тюнинг-base-line-модели)\n",
    "\n",
    "[САМОСТОЯТЕЛЬНО](#САМОСТОЯТЕЛЬНО)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Библиотеки и утилиты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, LSTM, TimeDistributed\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from hyperopt import hp, tpe, space_eval\n",
    "from hyperopt.fmin import fmin\n",
    "pd.set_option('display.max_columns', None)\n",
    "print('tensorflow version:', tf.__version__)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpu_devices:\n",
    "    for gpu_device in gpu_devices:\n",
    "        print('device available:', gpu_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = './models'\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    os.mkdir(MODEL_PATH)\n",
    "\n",
    "def set_all_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "set_all_seeds(2035)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Визуальный анализ данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cpt_power_data.csv', sep='\\t', encoding='utf-8', index_col=0)\n",
    "df['timestamp_value'] = pd.to_datetime(df['timestamp_value'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df:\n",
    "    print(f'{col}:', len(df[col].unique()), '| sample:', df[col].unique()[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "for ch_serial in df['measuringpoint_serial'].unique():\n",
    "    plt.plot(df[df['measuringpoint_serial'] == ch_serial].timestamp_value, \n",
    "             df[df['measuringpoint_serial'] == ch_serial].value_text, \n",
    "             label=ch_serial)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Один ряд как пример"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_serial = df['measuringpoint_serial'].unique()[0]\n",
    "channel = pd.DataFrame(\n",
    "    data=list(df[df['measuringpoint_serial'] == ch_serial].value_text),\n",
    "    index=list(df[df['measuringpoint_serial'] == ch_serial].timestamp_value)\n",
    ")\n",
    "channel.columns = ['pwr']\n",
    "print(channel.shape)\n",
    "channel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 4))\n",
    "plt.plot(channel)\n",
    "plt.title(f'Channel No {ch_serial}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Немного новых признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мануал по datetime, полезно для признаков на основе дат https://docs.python.org/3/library/datetime.html#datetime.datetime.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel['n_day'] = channel.index.day.astype(np.int8)\n",
    "channel['n_week'] = channel.index.week.astype(np.int8)\n",
    "channel['n_month'] = channel.index.month.astype(np.int8)\n",
    "channel['w_day'] = channel.index.weekday.astype(np.int8)\n",
    "channel['is_weekend'] = (channel['w_day'] >= 5).astype(np.int8)\n",
    "channel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(16, 6))\n",
    "\n",
    "ax1.set_xlabel('time')\n",
    "ax1.set_ylabel('power')\n",
    "ax1.plot(channel.index, channel.pwr, label='power', color='grey')\n",
    "ax1.tick_params(axis='y')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('days')\n",
    "for col in [x for x in channel.columns if '_' in x]:\n",
    "    ax2.plot(channel.index, channel[col], label=col)\n",
    "ax2.tick_params(axis='y')\n",
    "\n",
    "fig.legend()\n",
    "plt.title('Channel: power and time features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base-line модель: подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полезная статья по LSTM для прогнозирования временных рядов https://machinelearningmastery.com/how-to-develop-lstm-models-for-time-series-forecasting/\n",
    "\n",
    "Статья про аналогичную задачу https://machinelearningmastery.com/how-to-develop-lstm-models-for-multi-step-time-series-forecasting-of-household-power-consumption/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler, scaler_pwr = MinMaxScaler(feature_range=(0, 1)), MinMaxScaler(feature_range=(0, 1))\n",
    "scaler_pwr.fit(channel['pwr'].values.reshape(-1, 1))\n",
    "with open(f'{MODEL_PATH}/scaler_pwr.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler_pwr, file)\n",
    "channel = scaler.fit_transform(channel)\n",
    "print('total elements:', len(channel))\n",
    "print('one element of channel:', channel[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(series, col_look, look_back, look_fwd, cols_features):\n",
    "    X, y = [], []\n",
    "    for i in range(len(series[:, col_look]) - look_back - look_fwd):\n",
    "        temp_X = []\n",
    "        temp_X.append(series[:, col_look][i:(i + look_back)])\n",
    "        for col in cols_features:\n",
    "            temp_X.append(series[:, col][(i + look_fwd):(i + look_back + look_fwd)])\n",
    "        X.append(temp_X)\n",
    "        y.append(series[:, col_look][(i + look_back):(i + look_back + look_fwd)])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_fwd = 7 * 24 * 2 # days * hours * half an hour\n",
    "print('look forward:', look_fwd)\n",
    "look_back = 2 * look_fwd \n",
    "print('look back:', look_back)\n",
    "X, y = get_dataset(channel, 0, look_back, look_fwd, [1, 2, 3, 4, 5])\n",
    "print('X shape:', X.shape, '| y shape:', y.shape)\n",
    "print('train sample:', X[0][:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(X, y, test_size=.25):\n",
    "    cut = int((1 - test_size) * len(y))\n",
    "    X_train, y_train = X[:cut], y[:cut]\n",
    "    X_test, y_test = X[cut:], y[cut:]\n",
    "    \n",
    "    # LSTM feed [samples, time steps, features]\n",
    "    print('as is:')\n",
    "    print('\\tX train shape:', X_train.shape, '| X test shape:', X_test.shape)\n",
    "    print('\\ty train shape:', y_train.shape, '| y test shape:', y_test.shape)\n",
    "    print('\\nreshaped to LSTM pattern [samples, time steps, features]:')\n",
    "    X_train = np.array([x.T for x in X_train])\n",
    "    X_test = np.array([x.T for x in X_test])\n",
    "    print('\\tX train shape:', X_train.shape, '| X test shape:', X_test.shape)\n",
    "    print('\\ty train shape:', y_train.shape, '| y test shape:', y_test.shape)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = get_train_test(X, y, test_size=.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base-line модель: обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(units, n_features, dropout,\n",
    "              look_back, look_fwd,\n",
    "              stack=False, loss='mse'):\n",
    "    model = Sequential()\n",
    "    if stack:\n",
    "        model.add(LSTM(units=units, \n",
    "                       input_shape=(look_back, n_features), \n",
    "                       return_sequences=True, \n",
    "                       dropout=dropout, \n",
    "                       recurrent_dropout=dropout))\n",
    "        model.add(LSTM(units=units,\n",
    "                       dropout=dropout, \n",
    "                       recurrent_dropout=dropout))\n",
    "    else:\n",
    "        model.add(LSTM(units=units, \n",
    "                       input_shape=(look_back, n_features),\n",
    "                       dropout=dropout, \n",
    "                       recurrent_dropout=dropout))\n",
    "    model.add(Dense(look_fwd))\n",
    "    model.add(Activation('linear'))\n",
    "    adam = optimizers.Adam(lr=.001, clipvalue=.5, clipnorm=1)\n",
    "    model.compile(loss=loss, optimizer=adam)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(\n",
    "    units=256, \n",
    "    n_features=6, \n",
    "    dropout=.4,\n",
    "    look_back=look_back, \n",
    "    look_fwd=look_fwd,\n",
    "    stack=False, \n",
    "    loss='mse'\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "checkpoint_path = f'{MODEL_PATH}/model.hdf5'\n",
    "earlystopper = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=40, \n",
    "    verbose=1,\n",
    "    mode='min'\n",
    ")\n",
    "lrreducer = ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=.1, \n",
    "    patience=20, \n",
    "    verbose=1, \n",
    "    min_lr=1e-6,\n",
    "    mode='min'\n",
    ")\n",
    "checkpointer = ModelCheckpoint(\n",
    "    checkpoint_path, \n",
    "    monitor='val_loss', \n",
    "    verbose=1, \n",
    "    save_best_only=True,\n",
    "    save_weights_only=True, \n",
    "    mode='min'\n",
    ")\n",
    "callbacks = [earlystopper, checkpointer, lrreducer]\n",
    "history = model.fit(\n",
    "    X_train, y_train, \n",
    "    epochs=1000, \n",
    "    batch_size=128, \n",
    "    validation_data=(X_test, y_test), \n",
    "    verbose=1,\n",
    "    callbacks=callbacks,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 4))\n",
    "y_pred = model.predict(X_test[0:1])[0]\n",
    "plt.plot(y_test[0], label='true')\n",
    "plt.plot(y_pred, label='predict')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test[0:1])[0]\n",
    "\n",
    "with open(f'{MODEL_PATH}/scaler_pwr.pkl', 'rb') as f:\n",
    "    scaler_pwr = pickle.load(f)\n",
    "\n",
    "plt.figure(figsize=(16, 4))\n",
    "past = range(len(X_train[0][:, 0]))\n",
    "future = range(len(X_train[0][:, 0]), len(X_train[0][:, 0]) + len(y_test[0]))\n",
    "plt.plot(past, \n",
    "         scaler_pwr.inverse_transform(X_train[-1][:, 0].reshape(-1, 1)), \n",
    "         label='train')\n",
    "plt.plot(future, \n",
    "         scaler_pwr.inverse_transform(y_test[0].reshape(-1, 1)), \n",
    "         label='true')\n",
    "plt.plot(future, \n",
    "         scaler_pwr.inverse_transform(y_pred.reshape(-1, 1)), \n",
    "         label='predict')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_ = pd.DataFrame(\n",
    "    data=list(df[df['measuringpoint_serial'] == ch_serial].value_text),\n",
    "    index=list(df[df['measuringpoint_serial'] == ch_serial].timestamp_value)\n",
    ")\n",
    "plt.figure(figsize=(16, 4))\n",
    "start_point = len(X_train) + look_back\n",
    "plt.plot(channel_[(start_point - 2 * look_back):(start_point + len(y_pred))], \n",
    "         label='true')\n",
    "plt.plot(channel_.index[start_point:(start_point + len(y_pred))],\n",
    "         scaler_pwr.inverse_transform(y_pred.reshape(-1, 1)), \n",
    "         label='predict')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ОПЦИОНАЛЬНО: тюнинг base-line модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мануал по hyperopt https://hyperopt.github.io/hyperopt/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train, X_test, y_test,\n",
    "                units, n_features, dropout, stack,\n",
    "                loss='mae', patience=40, batch_size=128):\n",
    "    model = get_model(\n",
    "        units=units, \n",
    "        n_features=n_features, \n",
    "        dropout=dropout,\n",
    "        look_back=look_back, \n",
    "        look_fwd=look_fwd,\n",
    "        stack=stack, \n",
    "        loss=loss\n",
    "    )\n",
    "    checkpoint_path = f'{MODEL_PATH}/model.hdf5'\n",
    "    earlystopper = EarlyStopping(\n",
    "            monitor='val_loss', \n",
    "            patience=patience, \n",
    "            verbose=0,\n",
    "            mode='min'\n",
    "    )\n",
    "    lrreducer = ReduceLROnPlateau(\n",
    "        monitor='val_loss', \n",
    "        factor=.1, \n",
    "        patience=int(patience / 2), \n",
    "        verbose=0, \n",
    "        min_lr=1e-6,\n",
    "        mode='min'\n",
    "    )\n",
    "    checkpointer = ModelCheckpoint(\n",
    "        checkpoint_path, \n",
    "        monitor='val_loss', \n",
    "        verbose=0, \n",
    "        save_best_only=True,\n",
    "        save_weights_only=True, \n",
    "        mode='min'\n",
    "    )\n",
    "    callbacks = [earlystopper, checkpointer, lrreducer]\n",
    "    history = model.fit(\n",
    "        X_train, y_train, \n",
    "        epochs=1000, \n",
    "        batch_size=batch_size, \n",
    "        validation_data=(X_test, y_test), \n",
    "        verbose=2,\n",
    "        callbacks=callbacks,\n",
    "        shuffle=False\n",
    "    )\n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS = {\n",
    "    'units': 128,\n",
    "    'dropout': .4,\n",
    "    'stack': False\n",
    "}\n",
    "space = {\n",
    "    'units': hp.choice('units', [64, 128, 256]),\n",
    "    'dropout': hp.quniform('dropout', 0, .5, .01),\n",
    "    'stack': hp.choice('stack', [True, False])\n",
    "}\n",
    "MAX_EVALS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PARAMS_OPT = PARAMS.copy()\n",
    "best_model = None\n",
    "best_metric = 10e8\n",
    "\n",
    "def objective(params):\n",
    "    print('=' * 50, '\\n', '=' * 50)\n",
    "    global PARAMS_OPT, best_model, best_metric\n",
    "    PARAMS_OPT.update(params)\n",
    "    history, model = train_model(\n",
    "        X_train, y_train, X_test, y_test,\n",
    "        units=PARAMS_OPT['units'], \n",
    "        n_features=6, \n",
    "        dropout=PARAMS_OPT['dropout'], \n",
    "        stack=PARAMS_OPT['stack'],\n",
    "        loss='mae', \n",
    "        patience=10,\n",
    "        batch_size=128\n",
    "    )\n",
    "    metric = min(history.history['val_loss'])\n",
    "    if metric < best_metric:\n",
    "        best_metric = metric\n",
    "        best_model = model\n",
    "    print(f'\\nparams: {params} | metric: {metric}\\n')\n",
    "    return metric\n",
    "\n",
    "best_hopt = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=MAX_EVALS)\n",
    "print('best search:', best_hopt, '\\nbest params:', space_eval(space, best_hopt))\n",
    "PARAMS_OPT.update(space_eval(space, best_hopt))\n",
    "\n",
    "params_file = f'{MODEL_PATH}/hopt_params.json'\n",
    "with open(params_file, 'w') as file:\n",
    "    json.dump(PARAMS_OPT, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 4))\n",
    "y_pred = best_model.predict(X_test[0:1])[0]\n",
    "plt.plot(y_test[0], label='true')\n",
    "plt.plot(y_pred, label='predict')\n",
    "plt.title(f'Best model predictions, best metric={best_metric:.4f}')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### САМОСТОЯТЕЛЬНО"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Прогноз на две недели для следующих рядов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предлагается изучить два ряда с номерами каналов [11202786, 13150883]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "for ch_serial in [11202786, 13150883]:\n",
    "    plt.plot(df[df['measuringpoint_serial'] == ch_serial].timestamp_value, \n",
    "             df[df['measuringpoint_serial'] == ch_serial].value_text, \n",
    "             label=ch_serial)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Эксперименты с дополнительными признаками"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно учесть:\n",
    "1. Фактор праздников (первая неделя мая)\n",
    "2. Погодные условия (температура)\n",
    "3. Фазы луны (ну а вдруг...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Тюнинг параметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно тюнить почти все:\n",
    "1. Размер батча\n",
    "2. Patience\n",
    "3. Learning rate\n",
    "4. Optimizer\n",
    "5. Архитектура сети (количество слоев, функция активации, GRU vs LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Оценка решения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По метрике __mean_squared_error__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Orange Python 3",
   "language": "python",
   "name": "orange"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
